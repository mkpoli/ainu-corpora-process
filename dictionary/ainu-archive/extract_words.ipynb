{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 国立アイヌ民族博物館アイヌ語アーカイブ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "DIGITAL_ARCHIVE_DIR = Path('../input/archive/')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "8d6e8d3e5f5841e7a12c5ca0cac93c72",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/6 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "data\\archive\\-.html\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c3e0b8628d9d4449a9cf45b9e5406122",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/19049 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "data\\archive\\a.html\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "faa54b16236e4317bf50ead67858e7c4",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/20273 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "data\\archive\\e.html\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "fedcf1d29c134bf78b5d82151c057ce0",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/17798 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "data\\archive\\i.html\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "98d9ea7df13b4fd6afdc533e99261ce1",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/16815 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "data\\archive\\o.html\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "63cc6a605dac434b84b5c44b2b70f9c3",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/15886 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "data\\archive\\u.html\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "ca2ccc2612e94921be1f6a37f471f12b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/14903 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "import regex as re\n",
                "\n",
                "from bs4 import BeautifulSoup\n",
                "\n",
                "\n",
                "columns = ['lemma', 'def', 'pron', 'tag']\n",
                "dictionary = set()\n",
                "\n",
                "from tqdm.notebook import tqdm\n",
                "\n",
                "for file in tqdm(list(DIGITAL_ARCHIVE_DIR.glob('*.html'))):\n",
                "    print(file)\n",
                "    with open(file, 'r') as f:\n",
                "        file_tag = file.stem\n",
                "        \n",
                "        # remove unnecessary spaces\n",
                "        html = f.read().replace('\\n', '')\n",
                "        html = re.sub(r'\\s+', ' ', html)\n",
                "\n",
                "        soup = BeautifulSoup(html, 'html.parser')\n",
                "        dl = soup.find('dl')\n",
                "        if not dl:\n",
                "            raise Exception(f'No dl element found in {file}')\n",
                "        for dt, dd in tqdm(list(zip(dl.find_all('dt'), dl.find_all('dd')))):\n",
                "            # Extract the key and sound URL from the dt element\n",
                "            if sup := dt.find('sup'):\n",
                "                sup.extract()\n",
                "            key = dt.text.strip()\n",
                "            \n",
                "            sound_a = dt.find('a', class_='sound')\n",
                "            sound_url = sound_a['data-sound-url'] if sound_a else None\n",
                "            \n",
                "            # Extract the value from the dd element\n",
                "            value = dd.text.strip()\n",
                "\n",
                "            dictionary.add((key, value, sound_url, file_tag))\n",
                "\n",
                "import pandas as pd\n",
                "\n",
                "pd.DataFrame(dictionary, columns=columns).dropna(subset=['lemma']).reset_index(drop=True).sort_values('lemma').reset_index(drop=True).drop_duplicates().reset_index(drop=True).to_csv(DIGITAL_ARCHIVE_DIR / 'dictionary.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mregex\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDIGITAL_ARCHIVE_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdictionary.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlemma\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# df[df['def'].apply(lambda x: re.search(r'^[\\p{Katakana}\\-]', x) is None)].to_csv('./result.csv')\u001b[39;00m\n\u001b[0;32m      5\u001b[0m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdef\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m（出典：.*?、方言：.*?）$\u001b[39m\u001b[38;5;124m'\u001b[39m, x) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)]\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./result.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
                        "File \u001b[1;32mc:\\Users\\mk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
                        "File \u001b[1;32mc:\\Users\\mk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:678\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    663\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    664\u001b[0m     dialect,\n\u001b[0;32m    665\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    674\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    675\u001b[0m )\n\u001b[0;32m    676\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[1;32mc:\\Users\\mk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:581\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[1;32mc:\\Users\\mk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1253\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1251\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1253\u001b[0m     index, columns, col_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1254\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
                        "File \u001b[1;32mc:\\Users\\mk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:225\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 225\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    227\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
                        "File \u001b[1;32mc:\\Users\\mk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:805\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
                        "File \u001b[1;32mc:\\Users\\mk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:883\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
                        "File \u001b[1;32mc:\\Users\\mk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1026\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
                        "File \u001b[1;32mc:\\Users\\mk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1072\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
                        "File \u001b[1;32mc:\\Users\\mk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1147\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
                        "File \u001b[1;32mc:\\Users\\mk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\dtypes\\common.py:1474\u001b[0m, in \u001b[0;36mis_extension_array_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_extension_array_dtype\u001b[39m(arr_or_dtype) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m   1430\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1431\u001b[0m \u001b[38;5;124;03m    Check if an object is a pandas extension array type.\u001b[39;00m\n\u001b[0;32m   1432\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1472\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[0;32m   1473\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1474\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marr_or_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr_or_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1475\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[0;32m   1476\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import regex as re\n",
                "df = pd.read_csv(DIGITAL_ARCHIVE_DIR / 'dictionary.csv').dropna(subset=['lemma'])\n",
                "# df[df['def'].apply(lambda x: re.search(r'^[\\p{Katakana}\\-]', x) is None)].to_csv('./result.csv')\n",
                "df[df['def'].apply(lambda x: re.search(r'（出典：.*?、方言：.*?）$', x) is None)].to_csv('./result.csv')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "ename": "KeyError",
                    "evalue": "'pos'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
                        "\u001b[1;32mc:\\Users\\mk\\Google Drive Sync\\Python\\Language\\linguistics\\ainu\\dictionary.ipynb セル 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell://tunnel%2Bmkpoli/c%3A/Users/mk/Google%20Drive%20Sync/Python/Language/linguistics/ainu/dictionary.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m df\u001b[39m.\u001b[39;49mvalue_counts(\u001b[39m'\u001b[39;49m\u001b[39mpos\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
                        "File \u001b[1;32mc:\\Users\\mk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:6579\u001b[0m, in \u001b[0;36mDataFrame.value_counts\u001b[1;34m(self, subset, normalize, sort, ascending, dropna)\u001b[0m\n\u001b[0;32m   6576\u001b[0m \u001b[39mif\u001b[39;00m subset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   6577\u001b[0m     subset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m-> 6579\u001b[0m counts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroupby(subset, dropna\u001b[39m=\u001b[39;49mdropna)\u001b[39m.\u001b[39mgrouper\u001b[39m.\u001b[39msize()\n\u001b[0;32m   6581\u001b[0m \u001b[39mif\u001b[39;00m sort:\n\u001b[0;32m   6582\u001b[0m     counts \u001b[39m=\u001b[39m counts\u001b[39m.\u001b[39msort_values(ascending\u001b[39m=\u001b[39mascending)\n",
                        "File \u001b[1;32mc:\\Users\\mk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:7721\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   7716\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m   7718\u001b[0m \u001b[39m# https://github.com/python/mypy/issues/7642\u001b[39;00m\n\u001b[0;32m   7719\u001b[0m \u001b[39m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[39;00m\n\u001b[0;32m   7720\u001b[0m \u001b[39m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[39;00m\n\u001b[1;32m-> 7721\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[0;32m   7722\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   7723\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[0;32m   7724\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   7725\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   7726\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[0;32m   7727\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m   7728\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[0;32m   7729\u001b[0m     squeeze\u001b[39m=\u001b[39;49msqueeze,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   7730\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m   7731\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[0;32m   7732\u001b[0m )\n",
                        "File \u001b[1;32mc:\\Users\\mk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:882\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgroupby\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrouper\u001b[39;00m \u001b[39mimport\u001b[39;00m get_grouper\n\u001b[1;32m--> 882\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[0;32m    883\u001b[0m         obj,\n\u001b[0;32m    884\u001b[0m         keys,\n\u001b[0;32m    885\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    886\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m    887\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    888\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m    889\u001b[0m         mutated\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmutated,\n\u001b[0;32m    890\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[0;32m    893\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[0;32m    894\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
                        "File \u001b[1;32mc:\\Users\\mk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py:882\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    880\u001b[0m         in_axis, level, gpr \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, gpr, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 882\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m    883\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouper) \u001b[39mand\u001b[39;00m gpr\u001b[39m.\u001b[39mkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[39m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     exclusions\u001b[39m.\u001b[39madd(gpr\u001b[39m.\u001b[39mkey)\n",
                        "\u001b[1;31mKeyError\u001b[0m: 'pos'"
                    ]
                }
            ],
            "source": [
                "# count all words in the dictionary in pos column   "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Clean up the dictionary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "ename": "FileNotFoundError",
                    "evalue": "[Errno 2] No such file or directory: 'data/archive/dictionary.csv'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      3\u001b[0m df_archive \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marchive\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdictionary.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlemma\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;241m.\u001b[39mdrop_duplicates(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlemma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m HALF_WIDTH_KANA_2_SMALL_KANA \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mｸ\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mㇰ\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mｼ\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mㇱ\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mﾛ\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mㇿ\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m }\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Replace half-width katakana with small katakana\u001b[39;00m\n",
                        "File \u001b[0;32m~/projects/Ainu/ainu-corpora-process/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/projects/Ainu/ainu-corpora-process/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
                        "File \u001b[0;32m~/projects/Ainu/ainu-corpora-process/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/projects/Ainu/ainu-corpora-process/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
                        "File \u001b[0;32m~/projects/Ainu/ainu-corpora-process/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
                        "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/archive/dictionary.csv'"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "df_archive = (\n",
                "    pd.read_csv(DIGITAL_ARCHIVE_DIR/ \"dictionary.csv\")\n",
                "    .dropna(subset=[\"lemma\"])\n",
                "    .drop_duplicates(subset=[\"lemma\", \"def\"])\n",
                "    .reset_index(drop=True)\n",
                ")\n",
                "\n",
                "HALF_WIDTH_KANA_2_SMALL_KANA = {\n",
                "    \"ｸ\": \"ㇰ\",\n",
                "    \"ｼ\": \"ㇱ\",\n",
                "    \"ｽ\": \"ㇲ\",\n",
                "    \"ﾄ\": \"ㇳ\",\n",
                "    \"ﾇ\": \"ㇴ\",\n",
                "    \"ﾊ\": \"ㇵ\",\n",
                "    \"ﾋ\": \"ㇶ\",\n",
                "    \"ﾌﾟ\": \"ㇷ゚\",\n",
                "    \"ﾌ\": \"ㇷ\",\n",
                "    \"ﾍ\": \"ㇸ\",\n",
                "    \"ﾎ\": \"ㇹ\",\n",
                "    \"ﾑ\": \"ㇺ\",\n",
                "    \"ﾗ\": \"ㇻ\",\n",
                "    \"ﾘ\": \"ㇼ\",\n",
                "    \"ﾙ\": \"ㇽ\",\n",
                "    \"ﾚ\": \"ㇾ\",\n",
                "    \"ﾛ\": \"ㇿ\",\n",
                "}\n",
                "\n",
                "\n",
                "# Replace half-width katakana with small katakana\n",
                "df_archive['def'] = df_archive['def'].apply(lambda x: re.sub(rf'({\"|\".join(HALF_WIDTH_KANA_2_SMALL_KANA.keys())})', lambda m: HALF_WIDTH_KANA_2_SMALL_KANA[m.group(1)], x))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_archive[[\"lemma\", \"def\"]].to_csv(\n",
                "    DIGITAL_ARCHIVE_DIR / \"cleaned-dictionary.tsv\", sep=\"\\t\", index=False\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "26904\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>lemma</th>\n",
                            "      <th>def</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>(a-)ekonramu-sitne</td>\n",
                            "      <td>エコンラムシッネ §245．きぜつする（気絶する）；気が遠くなる；気を失う；人事不省になる(13)うつらうつらする[気を失ってから我に返る直前の半意識の状態にある](a-)ekonramu-sitne〔e-kón-ra-mu-šit-ne エこンラム･シッネ〕[a-(我)、e(それについて)、kon(&lt;kor 持っている)、ramu(その心･心臓〔が〕)、sit(糸などのもつれた玉)、ne(のようになる)]｟ホロベツ,サル―ユ研Ⅱ, pp.466〜467｠ （出典：知里人間編I、方言：）</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>(a-)ekonramu-tanak-tanak</td>\n",
                            "      <td>エコンラムタナㇰタナㇰ §245．きぜつする（気絶する）；気が遠くなる；気を失う；人事不省になる(12)うつらうつらする[気を失ってから我に返ろうとする前の半意識の状態、ゆめうつつの状態にある](a-)ekonramu-tanak-tanak〔エこンラム･たナㇰタナㇰ〕[a-(我)、e(それについて)、kon(&lt;kor もっている、自分の)、ramu(その心〔が〕]、tanak-tanak(うつらうつらする)&gt;｟サル―ユ研Ⅱ、 p.599｠ （出典：知里人間編I、方言：）</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>-a</td>\n",
                            "      <td>ア 【接尾】[名詞の所属形形成](所属語尾とも呼ぶ。 母音 a ア + 子音に終る語幹のうちのあるものにつく。 この母音がついて所属形の｢短い形｣ができる。 さらにその後に ha ハ がついて(つまり語幹に -aha アハ がついて)所属形の｢長い形｣がつくられる。 本辞典では長短二つの形を合わせて…a(ha) のように表記してある｡) sar サㇻ [概]尾；sara(ha) サラ(ハ) [所]…の尾。 （出典：田村、方言：沙流）</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>-aha</td>\n",
                            "      <td>アハ 【接尾】[名詞の所属形形成](｢所属語尾｣とも呼ぶ。 所属形の｢長い形｣をつくる｡) ☞-a ア （出典：田村、方言：沙流）</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>-ar</td>\n",
                            "      <td>アㇻ 【接尾】[不定使役形接尾辞](＝-yar ヤㇻ)(子音の後で y が落ちた形。 母音の後では -yar ヤㇻ の形が使われる｡) kar カㇻ …をつくる；karar カラㇻ …を人につくってもらう。 （出典：田村、方言：沙流）</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                      lemma  \\\n",
                            "0        (a-)ekonramu-sitne   \n",
                            "1  (a-)ekonramu-tanak-tanak   \n",
                            "2                        -a   \n",
                            "3                      -aha   \n",
                            "4                       -ar   \n",
                            "\n",
                            "                                                                                                                                                                                                                                                      def  \n",
                            "0  エコンラムシッネ §245．きぜつする（気絶する）；気が遠くなる；気を失う；人事不省になる(13)うつらうつらする[気を失ってから我に返る直前の半意識の状態にある](a-)ekonramu-sitne〔e-kón-ra-mu-šit-ne エこンラム･シッネ〕[a-(我)、e(それについて)、kon(<kor 持っている)、ramu(その心･心臓〔が〕)、sit(糸などのもつれた玉)、ne(のようになる)]｟ホロベツ,サル―ユ研Ⅱ, pp.466〜467｠ （出典：知里人間編I、方言：）  \n",
                            "1          エコンラムタナㇰタナㇰ §245．きぜつする（気絶する）；気が遠くなる；気を失う；人事不省になる(12)うつらうつらする[気を失ってから我に返ろうとする前の半意識の状態、ゆめうつつの状態にある](a-)ekonramu-tanak-tanak〔エこンラム･たナㇰタナㇰ〕[a-(我)、e(それについて)、kon(<kor もっている、自分の)、ramu(その心〔が〕]、tanak-tanak(うつらうつらする)>｟サル―ユ研Ⅱ、 p.599｠ （出典：知里人間編I、方言：）  \n",
                            "2                              ア 【接尾】[名詞の所属形形成](所属語尾とも呼ぶ。 母音 a ア + 子音に終る語幹のうちのあるものにつく。 この母音がついて所属形の｢短い形｣ができる。 さらにその後に ha ハ がついて(つまり語幹に -aha アハ がついて)所属形の｢長い形｣がつくられる。 本辞典では長短二つの形を合わせて…a(ha) のように表記してある｡) sar サㇻ [概]尾；sara(ha) サラ(ハ) [所]…の尾。 （出典：田村、方言：沙流）  \n",
                            "3                                                                                                                                                                                       アハ 【接尾】[名詞の所属形形成](｢所属語尾｣とも呼ぶ。 所属形の｢長い形｣をつくる｡) ☞-a ア （出典：田村、方言：沙流）  \n",
                            "4                                                                                                                                   アㇻ 【接尾】[不定使役形接尾辞](＝-yar ヤㇻ)(子音の後で y が落ちた形。 母音の後では -yar ヤㇻ の形が使われる｡) kar カㇻ …をつくる；karar カラㇻ …を人につくってもらう。 （出典：田村、方言：沙流）  "
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "cleaned_dictionary = pd.read_csv(DIGITAL_ARCHIVE_DIR/ 'cleaned-dictionary.tsv', sep='\\t')\n",
                "\n",
                "print(len(cleaned_dictionary))\n",
                "\n",
                "pd.set_option('display.max_colwidth',1000)\n",
                "cleaned_dictionary.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\mk\\AppData\\Local\\Temp\\ipykernel_44392\\1546722303.py:6: SettingWithCopyWarning: \n",
                        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                        "Try using .loc[row_indexer,col_indexer] = value instead\n",
                        "\n",
                        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                        "  tamura_entries.loc[:, 'def'] = tamura_entries['def'].apply(lambda x: re.sub(r'（出典：田村、方言：沙流）', '', x))\n"
                    ]
                }
            ],
            "source": [
                "# Find all 田村's in the dictionary (ending with 田村)\n",
                "\n",
                "tamura_entries = cleaned_dictionary.loc[cleaned_dictionary['def'].str.contains('（出典：田村、方言：沙流）')]\n",
                "\n",
                "# Remove the citation from the definition\n",
                "tamura_entries.loc[:, 'def'] = tamura_entries['def'].apply(lambda x: re.sub(r'（出典：田村、方言：沙流）', '', x))\n",
                "tamura_entries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\mk\\AppData\\Local\\Temp\\ipykernel_44392\\2980672500.py:1: SettingWithCopyWarning: \n",
                        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                        "Try using .loc[row_indexer,col_indexer] = value instead\n",
                        "\n",
                        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                        "  tamura_entries['translit'] = tamura_entries['def'].apply(lambda x: re.match(r'(.*?)(【.*)', x).group(1) if re.match(r'(.*?)(【.*)', x) else re.match(r'(\\p{scx=Katakana}+)', x).group(1))\n",
                        "C:\\Users\\mk\\AppData\\Local\\Temp\\ipykernel_44392\\2980672500.py:2: SettingWithCopyWarning: \n",
                        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                        "Try using .loc[row_indexer,col_indexer] = value instead\n",
                        "\n",
                        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                        "  tamura_entries['def'] = tamura_entries['def'].apply(lambda x: re.match(r'(.*?)(【.*)', x).group(2) if re.match(r'(.*?)(【.*)', x) else re.match(r'(\\p{scx=Katakana}+)', x).group(1))\n"
                    ]
                }
            ],
            "source": [
                "tamura_entries['translit'] = tamura_entries['def'].apply(lambda x: re.match(r'(.*?)(【.*)', x).group(1) if re.match(r'(.*?)(【.*)', x) else re.match(r'(\\p{scx=Katakana}+)', x).group(1))\n",
                "tamura_entries['def'] = tamura_entries['def'].apply(lambda x: re.match(r'(.*?)(【.*)', x).group(2) if re.match(r'(.*?)(【.*)', x) else re.match(r'(\\p{scx=Katakana}+)', x).group(1))\n",
                "tamura_entries = tamura_entries[['lemma', 'translit', 'def']]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "tamura_entries.to_csv(DIGITAL_ARCHIVE_DIR / \"tamura-entries.tsv\", sep=\"\\t\", index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>lemma</th>\n",
                            "      <th>translit</th>\n",
                            "      <th>def</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>-a</td>\n",
                            "      <td>ア</td>\n",
                            "      <td>【接尾】[名詞の所属形形成](所属語尾とも呼ぶ。 母音 a ア + 子音に終る語幹のうちのあ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>-aha</td>\n",
                            "      <td>アハ</td>\n",
                            "      <td>【接尾】[名詞の所属形形成](｢所属語尾｣とも呼ぶ。 所属形の｢長い形｣をつくる｡) ☞-a ア</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>-ar</td>\n",
                            "      <td>アㇻ</td>\n",
                            "      <td>【接尾】[不定使役形接尾辞](＝-yar ヤㇻ)(子音の後で y が落ちた形。 母音の後では...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>-asnu</td>\n",
                            "      <td>アㇱヌ</td>\n",
                            "      <td>【接尾】(語根またはそれから派生した語基に接尾して､ 性質を表す自動詞(形容詞)をつくる｡)...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>-atki</td>\n",
                            "      <td>アッキ</td>\n",
                            "      <td>【接尾】(自動詞をつくる。 限られた決まった語にのみ現われる｡)tusus トゥスㇱ (擬態...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9922</th>\n",
                            "      <td>útek</td>\n",
                            "      <td>ウテㇰ</td>\n",
                            "      <td>【他動】(人)を使いにやる､ (人)を(使い走りの仕事に)使う。 póho útek haw...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9923</th>\n",
                            "      <td>útur</td>\n",
                            "      <td>ウトゥㇽ</td>\n",
                            "      <td>【位名】[概](所は útur(u)ke(he) ウトゥル/ウトゥㇽ/ウトゥルケ(ヘ)/ウト...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9924</th>\n",
                            "      <td>útur(u)ke(he)</td>\n",
                            "      <td>ウトゥㇽケ(ヘ)/ウトゥルケ(ヘ)</td>\n",
                            "      <td>【位名】[所](概は útur ウトゥㇽ)[utur-u-ke …の下座・(所属語尾)・(よ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9925</th>\n",
                            "      <td>úturke</td>\n",
                            "      <td>ウトゥㇽケ</td>\n",
                            "      <td>【位名】☞útur(u)ke(he) ウトゥㇽケ(ヘ)/ウトゥルケ(ヘ)</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9926</th>\n",
                            "      <td>úwa</td>\n",
                            "      <td>ウワ</td>\n",
                            "      <td>【間投】知らない､ わからない。 ☞uwa ウワ 1</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>9927 rows × 3 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "              lemma            translit  \\\n",
                            "0                -a                  ア    \n",
                            "1              -aha                 アハ    \n",
                            "2               -ar                 アㇻ    \n",
                            "3             -asnu                アㇱヌ    \n",
                            "4             -atki                アッキ    \n",
                            "...             ...                 ...   \n",
                            "9922           útek                ウテㇰ    \n",
                            "9923           útur               ウトゥㇽ    \n",
                            "9924  útur(u)ke(he)  ウトゥㇽケ(ヘ)/ウトゥルケ(ヘ)    \n",
                            "9925         úturke              ウトゥㇽケ    \n",
                            "9926            úwa                 ウワ    \n",
                            "\n",
                            "                                                    def  \n",
                            "0     【接尾】[名詞の所属形形成](所属語尾とも呼ぶ。 母音 a ア + 子音に終る語幹のうちのあ...  \n",
                            "1     【接尾】[名詞の所属形形成](｢所属語尾｣とも呼ぶ。 所属形の｢長い形｣をつくる｡) ☞-a ア   \n",
                            "2     【接尾】[不定使役形接尾辞](＝-yar ヤㇻ)(子音の後で y が落ちた形。 母音の後では...  \n",
                            "3     【接尾】(語根またはそれから派生した語基に接尾して､ 性質を表す自動詞(形容詞)をつくる｡)...  \n",
                            "4     【接尾】(自動詞をつくる。 限られた決まった語にのみ現われる｡)tusus トゥスㇱ (擬態...  \n",
                            "...                                                 ...  \n",
                            "9922  【他動】(人)を使いにやる､ (人)を(使い走りの仕事に)使う。 póho útek haw...  \n",
                            "9923  【位名】[概](所は útur(u)ke(he) ウトゥル/ウトゥㇽ/ウトゥルケ(ヘ)/ウト...  \n",
                            "9924  【位名】[所](概は útur ウトゥㇽ)[utur-u-ke …の下座・(所属語尾)・(よ...  \n",
                            "9925              【位名】☞útur(u)ke(he) ウトゥㇽケ(ヘ)/ウトゥルケ(ヘ)   \n",
                            "9926                        【間投】知らない､ わからない。 ☞uwa ウワ 1   \n",
                            "\n",
                            "[9927 rows x 3 columns]"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "tamura_entries = pd.read_csv(DIGITAL_ARCHIVE_DIR / \"tamura-entries.tsv\", sep=\"\\t\")\n",
                "tamura_entries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.7"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
